version: "0.1"
default_model:
    model: claude-3-haiku-20240307

flow:
  clean_input:
    lambda: |
      ''.join(char for char in ' '.join(player_input.split()) if char.isprintable())

  memories:
    text: |
      {% for memory in available_memories %}
      - {{ memory.text }}
      {% endfor %}
  
  triggers_string:
    text: |
      {{ triggers|join(', ') }}

  ask_about_stability:
    action: llm
    model:
      temperature: 0.2
      max_output_tokens: 300
    prompt:
      - text: |
          You are evaluating a player's response in an interactive narrative. Your task is to determine:
          1. How well it maintains narrative coherence
          2. How likely it is to lead to discovering available memories

      - var: current_paragraph
        heading: Current story context
      - link: memories
        heading: Available memories that could be discovered
      - var: clean_input
        heading: Player response

      - text: |
          Scoring criteria (0.0-1.0):
          OPTIMAL (0.7-1.0):
          - Response shows deep understanding of context
          - Naturally leads to discovering available memories
          - Strong thematic alignment
  
          STABLE (0.5-0.6):
          - Response maintains narrative coherence
          - May indirectly relate to memories
          - Good thematic fit
  
          UNSTABLE (0.3-0.4):
          - Limited connection to context
          - Unlikely to trigger memories
          - Weak thematic alignment
  
          DANGEROUS (0.1-0.2):
          - Breaks narrative flow
          - Actively prevents memory discovery
          - Poor thematic fit
  
          CRITICAL (0.0-0.1):
          - Completely disconnected from narrative
          - Makes memory discovery impossible
          - No thematic relevance
  
          First, analyze how the response relates to the context and available memories.

  calculate_stability:
    action: llm
    model:
      model: gpt-4o-mini
      temperature: 0.2
      max_output_tokens: 10
    prompt:
      - link: ask_about_stability
      - Output a number between 0.0 and 1.0 that represents the stability score.
    output_schema:
      stability:
        type: number

  stability:
    lambda: calculate_stability.data.stability
    
  new_temp:
    lambda: 0.3 + ((1 - stability) * 0.7)

  generate_narrative_response:
    action: llm
    model:
      temperature:
        var: new_temp
      max_output_tokens: 1000
    quote_style: xml
    prompt:
      - You are an interactive narrative engine. Generate a response to the player's input that maintains narrative coherence while reflecting the current stability level ({{ stability }}).

      - var: current_paragraph
        heading: Current narrative context
    #   - var: nearby_segments
    #     heading: Relevant narrative elements (with relevance scores)
      - var: player_input
        heading: Player input
    #   - var: state_history
    #     heading: Recent state history

      - |
        Rules:
        - If stability is high ({{ stability }} > 0.7), maintain clear narrative coherence
        - If stability is medium (0.3 < {{ stability }} < 0.7), introduce subtle uncertainty
        - If stability is low ({{ stability }} < 0.3), incorporate narrative distortions
        - Keep the response length similar to the original paragraph
        - Maintain the same writing style and tone as the original
        - Reference nearby narrative elements when relevant

        Generate a response paragraph, surrounded by <narrative_response> tags:
  narrative_response:
    action: extract_xml_tag
    tag: narrative_response
    text:
      stream: true
      link: generate_narrative_response

  check_memory_trigger:
    action: llm
    model:
      temperature: 0.2
      max_output_tokens: 100
    prompt:
      - Determine if this response should trigger a memory.

      - var: current_paragraph
        heading: Initial narrative context
      - var: memory_text
        heading: Memory
      - link: triggers_string
        heading: Relevant trigger phrases
      - var: clean_input
        heading: Player response

      - |
        Consider:
        1. Semantic similarity to memory content
        2. Presence of trigger phrases or similar concepts
        3. Narrative relevance

        Provide a brief explanation of your reasoning.
  does_memory_trigger:
    action: llm
    model:
      model: gpt-4o-mini
      temperature: 0.2
      max_output_tokens: 10
    prompt:
      - link: check_memory_trigger
      - Output a boolean indicating whether the response triggers the memory.
    output_schema:
      does_trigger:
        type: boolean
  memory_does_trigger:
    lambda: |
      does_memory_trigger.data.does_trigger

#   calculate_coherence:
#     action: prompt
#     model:
#       temperature: 0.2
#       max_tokens: 10
#     prompt: |
#       Analyze the narrative coherence between these two texts and provide a single number between 0 and 1, where:
#       - 1.0 means perfect narrative coherence and thematic alignment
#       - 0.0 means complete narrative disconnect

#       Story context:
#       {{ current_paragraph }}

#       Response:
#       {{ clean_input }}

#       Consider:
#       1. Thematic consistency
#       2. Narrative flow
#       3. Logical connection
#       4. Contextual relevance

#       Output only a single number between 0 and 1: